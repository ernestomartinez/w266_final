{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install rouge\n",
    "# !pip install sentencepiece\n",
    "# !pip install nomkl\n",
    "# !pip install datasets\n",
    "# !pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TFT5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import Dataset\n",
    "from rouge import Rouge\n",
    "import nltk.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some functions for convenience later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_story(filename):\n",
    "    \"\"\"Given the CNN data file, reformats to separate the story from the highlights.\n",
    "    Highlights are returned as a single string\"\"\"\n",
    "    \n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    \n",
    "    # split the story and highlights\n",
    "    split_text = text.split('\\n\\n@highlight\\n\\n')\n",
    "    source = '\\n\\n@highlight\\n\\n'.join(split_text[:-1])\n",
    "    target = split_text[-1]\n",
    "    \n",
    "    # return both, rejoining highlights as a single string\n",
    "    return source, target\n",
    "\n",
    "def cos_sims(out_sent, ref_sents):\n",
    "    \"gets cosine similarities for an output sentence with respect to the highlight sentences. Returns the sum of values.\"\n",
    "    \n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\")                                                                                                                                                                                                   \n",
    "    \n",
    "    # get sentence level vectors with tf-idf\n",
    "    tfidf = vect.fit_transform([out_sent] + ref_sents)\n",
    "    \n",
    "    # get similarity matrix\n",
    "    similarity_mat = tfidf * tfidf.T\n",
    "    \n",
    "    # only values comparing \"out_sent\" with each sent in \"ref_sents\"\n",
    "    return similarity_mat.toarray()[:1,1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a T5 Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5 model objects\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0001d1afc246a7964130f43ae940af6bc6c57f01.story',\n",
       " '0002095e55fcbd3a2f366d9bf92a95433dc305ef.story',\n",
       " '00027e965c8264c35cc1bc55556db388da82b07f.story',\n",
       " '0002c17436637c4fe1837c935c04de47adb18e9a.story',\n",
       " '0003ad6ef0c37534f80b55b4235108024b407f0b.story']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of story files in our dataset\n",
    "textFiles = os.listdir('cnn_stories_tokenized')\n",
    "textFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's official : U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria .\n",
      "\n",
      "Obama sent a letter to the heads of the House and Senate on Saturday night , hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons .\n",
      "\n",
      "The proposed legislation from Obama asks Congress to approve the use of military force `` to deter , disrupt , prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction . ''\n",
      "\n",
      "It 's a step that is set to turn an international crisis into a fierce domestic political battle .\n",
      "\n",
      "There are key questions looming over the debate : What did U.N. weapons inspectors find in Syria ? What happens if Congress votes no ? And how will the Syrian government react ?\n",
      "\n",
      "In a televised address from the White House Rose Garden earlier Saturday , the president said he would take his case to Congress , not because he has to -- but because he wants to .\n",
      "\n",
      "`` While I believe I have the authority to carry out this military action without specific congressional authorization , I know that the country will be stronger if we take this course , and our actions will be even more effective , '' he said . `` We should have this debate , because the issues are too big for business as usual . ''\n",
      "\n",
      "Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9 . The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday , Sen. Robert Menendez said .\n",
      "\n",
      "Transcript : Read Obama 's full remarks\n",
      "\n",
      "Syrian crisis : Latest developments\n",
      "\n",
      "U.N. inspectors leave Syria\n",
      "\n",
      "Obama 's remarks came shortly after U.N. inspectors left Syria , carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb .\n",
      "\n",
      "`` The aim of the game here , the mandate , is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom , '' U.N. spokesman Martin Nesirky told reporters on Saturday .\n",
      "\n",
      "But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis .\n",
      "\n",
      "Top U.S. officials have said there 's no doubt that the Syrian government was behind it , while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels .\n",
      "\n",
      "British and U.S. intelligence reports say the attack involved chemical weapons , but U.N. officials have stressed the importance of waiting for an official report from inspectors .\n",
      "\n",
      "The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban , who has said he wants to wait until the U.N. team 's final report is completed before presenting it to the U.N. Security Council .\n",
      "\n",
      "The Organization for the Prohibition of Chemical Weapons , which nine of the inspectors belong to , said Saturday that it could take up to three weeks to analyze the evidence they collected .\n",
      "\n",
      "`` It needs time to be able to analyze the information and the samples , '' Nesirky said .\n",
      "\n",
      "He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria , and that `` a military solution is not an option . ''\n",
      "\n",
      "Bergen : Syria is a problem from hell for the U.S.\n",
      "\n",
      "Obama : ` This menace must be confronted '\n",
      "\n",
      "Obama 's senior advisers have debated the next steps to take , and the president 's comments Saturday came amid mounting political pressure over the situation in Syria . Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire .\n",
      "\n",
      "Some global leaders have expressed support , but the British Parliament 's vote against military action earlier this week was a blow to Obama 's hopes of getting strong backing from key NATO allies .\n",
      "\n",
      "On Saturday , Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad . Any military attack would not be open-ended or include U.S. ground forces , he said .\n",
      "\n",
      "Syria 's alleged use of chemical weapons earlier this month `` is an assault on human dignity , '' the president said .\n",
      "\n",
      "A failure to respond with force , Obama argued , `` could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm . In a world with many dangers , this menace must be confronted . ''\n",
      "\n",
      "Syria missile strike : What would happen next ?\n",
      "\n",
      "Map : U.S. and allied assets around Syria\n",
      "\n",
      "Obama decision came Friday night\n",
      "\n",
      "On Friday night , the president made a last-minute decision to consult lawmakers .\n",
      "\n",
      "What will happen if they vote no ?\n",
      "\n",
      "It 's unclear . A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force .\n",
      "\n",
      "Obama on Saturday continued to shore up support for a strike on the al-Assad government .\n",
      "\n",
      "He spoke by phone with French President Francois Hollande before his Rose Garden speech .\n",
      "\n",
      "`` The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world , '' the White House said .\n",
      "\n",
      "Meanwhile , as uncertainty loomed over how Congress would weigh in , U.S. military officials said they remained at the ready .\n",
      "\n",
      "5 key assertions : U.S. intelligence report on Syria\n",
      "\n",
      "Syria : Who wants what after chemical weapons horror\n",
      "\n",
      "Reactions mixed to Obama 's speech\n",
      "\n",
      "A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama 's announcement .\n",
      "\n",
      "`` Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way , '' said spokesman Louay Safi . `` So we are quite concerned . ''\n",
      "\n",
      "Some members of Congress applauded Obama 's decision .\n",
      "\n",
      "House Speaker John Boehner , Majority Leader Eric Cantor , Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president .\n",
      "\n",
      "`` Under the Constitution , the responsibility to declare war lies with Congress , '' the Republican lawmakers said . `` We are glad the president is seeking authorization for any military action in Syria in response to serious , substantive questions being raised . ''\n",
      "\n",
      "More than 160 legislators , including 63 of Obama 's fellow Democrats , had signed letters calling for either a vote or at least a `` full debate '' before any U.S. action .\n",
      "\n",
      "British Prime Minister David Cameron , whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week , responded to Obama 's speech in a Twitter post Saturday .\n",
      "\n",
      "`` I understand and support Barack Obama 's position on Syria , '' Cameron said .\n",
      "\n",
      "An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory .\n",
      "\n",
      "`` The main reason Obama is turning to the Congress : the military operation did not get enough support either in the world , among allies of the US or in the United States itself , '' Alexei Pushkov , chairman of the international-affairs committee of the Russian State Duma , said in a Twitter post .\n",
      "\n",
      "In the United States , scattered groups of anti-war protesters around the country took to the streets Saturday .\n",
      "\n",
      "`` Like many other Americans ... we 're just tired of the United States getting involved and invading and bombing other countries , '' said Robin Rosecrans , who was among hundreds at a Los Angeles demonstration .\n",
      "\n",
      "What do Syria 's neighbors think ?\n",
      "\n",
      "Why Russia , China , Iran stand by Assad\n",
      "\n",
      "Syria 's government unfazed\n",
      "\n",
      "After Obama 's speech , a military and political analyst on Syrian state TV said Obama is `` embarrassed '' that Russia opposes military action against Syria , is `` crying for help '' for someone to come to his rescue and is facing two defeats -- on the political and military levels .\n",
      "\n",
      "Syria 's prime minister appeared unfazed by the saber-rattling .\n",
      "\n",
      "`` The Syrian Army 's status is on maximum readiness and fingers are on the trigger to confront all challenges , '' Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy , according to a banner on Syria State TV that was broadcast prior to Obama 's address .\n",
      "\n",
      "An anchor on Syrian state television said Obama `` appeared to be preparing for an aggression on Syria based on repeated lies . ''\n",
      "\n",
      "A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel , Turkey , some Arabs and right-wing extremists in the United States .\n",
      "\n",
      "`` I think he has done well by doing what Cameron did in terms of taking the issue to Parliament , '' said Bashar Jaafari , Syria 's ambassador to the United Nations .\n",
      "\n",
      "Both Obama and Cameron , he said , `` climbed to the top of the tree and do n't know how to get down . ''\n",
      "\n",
      "The Syrian government has denied that it used chemical weapons in the August 21 attack , saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it .\n",
      "\n",
      "British intelligence had put the number of people killed in the attack at more than 350 .\n",
      "\n",
      "On Saturday , Obama said `` all told , well over 1,000 people were murdered . '' U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429 , more than 400 of them children . No explanation was offered for the discrepancy .\n",
      "\n",
      "Iran : U.S. military action in Syria would spark ` disaster '\n",
      "\n",
      "Opinion : Why strikes in Syria are a bad idea\n",
      "\n",
      "@highlight\n",
      "\n",
      "Syrian official : Obama climbed to the top of the tree , `` does n't know how to get down ''\n",
      "\n",
      "@highlight\n",
      "\n",
      "Obama sends a letter to the heads of the House and Senate\n",
      "\n",
      "@highlight\n",
      "\n",
      "Obama to seek congressional approval on military action against Syria\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Aim is to determine whether CW were used , not by whom , says U.N. spokesman\n"
     ]
    }
   ],
   "source": [
    "story, highlight = format_story('cnn_stories_tokenized/'+textFiles[0])\n",
    "print(story)\n",
    "print('~'*50)\n",
    "print(highlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get some baseline loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2412 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1225, grad_fn=<NllLossBackward>)\n",
      "tensor(3.1754, grad_fn=<NllLossBackward>)\n",
      "tensor(3.9362, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8215, grad_fn=<NllLossBackward>)\n",
      "tensor(3.4645, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#text_files = ['example.story', 'example1.story', 'example2.story']\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('cnn_stories_tokenized/'+textFiles[i])\n",
    "    \n",
    "    #train the model\n",
    "    input_ids = tokenizer('summarize: ' + story, return_tensors='pt').input_ids\n",
    "    labels = tokenizer(highlights, return_tensors='pt').input_ids\n",
    "    \n",
    "    # compute loss (this returns an array of things)\n",
    "    loss = model(input_ids=input_ids, labels=labels).loss\n",
    "    \n",
    "    # print loss (sum of array values above)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on 1000 stories (for dev purposes only. We will use a full training set for the final report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 passed, 10 passed, 15 passed, 20 passed, 25 passed, 30 passed, 35 passed, 40 passed, 45 passed, 50 passed, 55 passed, 60 passed, 65 passed, 70 passed, 75 passed, 80 passed, 85 passed, 90 passed, 95 passed, 100 passed, 105 passed, 110 passed, 115 passed, 120 passed, 125 passed, 130 passed, 135 passed, 140 passed, 145 passed, 150 passed, 155 passed, 160 passed, 165 passed, 170 passed, 175 passed, 180 passed, 185 passed, 190 passed, 195 passed, 200 passed, 205 passed, 210 passed, 215 passed, 220 passed, 225 passed, 230 passed, 235 passed, 240 passed, 245 passed, 250 passed, 255 passed, 260 passed, 265 passed, 270 passed, 275 passed, 280 passed, 285 passed, 290 passed, 295 passed, 300 passed, 305 passed, 310 passed, 315 passed, 320 passed, 325 passed, 330 passed, 335 passed, 340 passed, 345 passed, 350 passed, 355 passed, 360 passed, 365 passed, 370 passed, 375 passed, 380 passed, 385 passed, 390 passed, 395 passed, 400 passed, 405 passed, 410 passed, 415 passed, 420 passed, 425 passed, 430 passed, 435 passed, 440 passed, 445 passed, 450 passed, 455 passed, 460 passed, 465 passed, 470 passed, 475 passed, 480 passed, 485 passed, 490 passed, 495 passed, 500 passed, 505 passed, 510 passed, 515 passed, 520 passed, 525 passed, 530 passed, 535 passed, 540 passed, 545 passed, 550 passed, 555 passed, 560 passed, 565 passed, 570 passed, 575 passed, 580 passed, 585 passed, 590 passed, 595 passed, 600 passed, 605 passed, 610 passed, 615 passed, 620 passed, 625 passed, 630 passed, 635 passed, 640 passed, 645 passed, 650 passed, 655 passed, 660 passed, 665 passed, 670 passed, 675 passed, 680 passed, 685 passed, 690 passed, 695 passed, 700 passed, 705 passed, 710 passed, 715 passed, 720 passed, 725 passed, 730 passed, 735 passed, 740 passed, 745 passed, 750 passed, 755 passed, 760 passed, 765 passed, 770 passed, 775 passed, 780 passed, 785 passed, 790 passed, 795 passed, 800 passed, 805 passed, 810 passed, 815 passed, 820 passed, 825 passed, 830 passed, 835 passed, 840 passed, 845 passed, 850 passed, 855 passed, 860 passed, 865 passed, 870 passed, 875 passed, 880 passed, 885 passed, 890 passed, 895 passed, 900 passed, 905 passed, 910 passed, 915 passed, 920 passed, 925 passed, 930 passed, 935 passed, 940 passed, 945 passed, 950 passed, 955 passed, 960 passed, 965 passed, 970 passed, 975 passed, 980 passed, 985 passed, 990 passed, 995 passed, 1000 passed, \n",
      "\n",
      "time: 0.9870738426844279\n"
     ]
    }
   ],
   "source": [
    "source_text = []\n",
    "target_text = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('cnn_stories_tokenized/'+textFiles[i])\n",
    "    \n",
    "    source_text.append(story)\n",
    "    target_text.append(highlights)\n",
    "    \n",
    "#     source_text.append(tokenizer('summarize: ' + story, return_tensors='tf').input_ids)\n",
    "#     target_text.append(tokenizer(highlights, return_tensors='tf').input_ids)\n",
    "    \n",
    "    if (i+1)%50 == 0:\n",
    "        print(i+1, \"passed\", end = ', ')\n",
    "        \n",
    "print('\\n\\ntime:', (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1k = pd.DataFrame(list(zip(source_text, target_text)),columns =['source', 'target'])\n",
    "train_1k = Dataset.from_pandas(train_1k)\n",
    "# train_1k.iloc[0,1]\n",
    "\n",
    "dataset = train_1k.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e118f29f77224a03a715c1428ccee1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8c00178d6f40e992a1fe9837507b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized_input = tokenizer(batch['source'], padding='max_length', truncation=True)\n",
    "    tokenized_label = tokenizer(batch['target'], padding='max_length', truncation=True)\n",
    "\n",
    "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
    "\n",
    "    return tokenized_input\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=512)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels', 'source', 'target'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 17:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.464000</td>\n",
       "      <td>0.155527</td>\n",
       "      <td>20.765000</td>\n",
       "      <td>4.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>20.754100</td>\n",
       "      <td>4.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.108892</td>\n",
       "      <td>20.845500</td>\n",
       "      <td>4.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.101462</td>\n",
       "      <td>20.779900</td>\n",
       "      <td>4.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.097633</td>\n",
       "      <td>20.882600</td>\n",
       "      <td>4.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>20.843400</td>\n",
       "      <td>4.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.096146</td>\n",
       "      <td>20.856500</td>\n",
       "      <td>4.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.094663</td>\n",
       "      <td>21.555000</td>\n",
       "      <td>4.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.093881</td>\n",
       "      <td>21.605700</td>\n",
       "      <td>4.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.093527</td>\n",
       "      <td>21.552000</td>\n",
       "      <td>4.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.093498</td>\n",
       "      <td>21.550500</td>\n",
       "      <td>4.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = 'model-Copy1'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "    prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "    learning_rate=0.001,\n",
    "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "    save_steps=10, # How often to save a checkpoint\n",
    "    save_total_limit=1, # Number of maximum checkpoints to save\n",
    "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "    run_name='run_name', # Wandb run name\n",
    "    logging_steps=10, # How often to log loss to wandb\n",
    "    eval_steps=10, # How often to run evaluation on the val_set\n",
    "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "    greater_is_better=False # Best model is the one with the lowest loss, not highest.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir + '/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How did Training affect the loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1583, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1307, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0575, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7447, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2165, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# SECOND LOOK\n",
    "\n",
    "our_model = T5ForConditionalGeneration.from_pretrained('model/model')\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('cnn_stories_tokenized/'+textFiles[i])\n",
    "    \n",
    "    #train the model\n",
    "    input_ids = tokenizer('summarize: ' + story, return_tensors='pt').input_ids\n",
    "    labels = tokenizer(highlights, return_tensors='pt').input_ids\n",
    "    \n",
    "    # compute loss (this returns an array of things)\n",
    "    loss = our_model(input_ids=input_ids, labels=labels).loss\n",
    "    \n",
    "    # print loss (sum of array values above)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('story_list.txt', 'w') as f:\n",
    "#     for item in textFiles:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Juventus have sacked coach Ciro Ferrara after a string of poor results. The Bianconeri have lost five of their last six games in Serie A and have slumped to sixth in the standings. Zaccheroni will guide this afternoon's training session before being officially unveiled.</s>\n",
      "======================================================================\n",
      "Liverpool manager Rafael Benitez has also been linked to the Turin giants\n"
     ]
    }
   ],
   "source": [
    "# format the text to input/target format\n",
    "story, highlights = format_story('cnn_stories_tokenized/'+textFiles[6001])\n",
    "\n",
    "# encode the summary\n",
    "encoded = tokenizer.encode('summarize: ' + story.replace('\\n',' '), return_tensors='pt')\n",
    "\n",
    "# decode\n",
    "output = our_model.generate(encoded, num_beams=4, no_repeat_ngram_size=2,\n",
    "                         min_length=10, max_length=400, early_stopping=True)\n",
    "summary = tokenizer.decode(output[0])\n",
    "\n",
    "print(summary)\n",
    "print('='*70)\n",
    "print(highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-LRB- CNN -RRB- -- Juventus have sacked coach Ciro Ferrara after a string of poor results and have installed Alberto Zaccheroni in the hot seat until the end of the season .\n",
      "\n",
      "Ferrara 's position has been threatened after a dismal run which has seen them slip out of contention in the Serie A title race as well as being eliminated from the Champions League at the group stages .\n",
      "\n",
      "Thursday 's 2-1 Coppa Italia defeat to Italian champions Inter Milan proved the final straw and the club released a statement to confirm his departure and Zaccheroni 's arrival .\n",
      "\n",
      "`` Zaccheroni will take over the team immediately and will guide this afternoon 's training session in Vinovo before being officially unveiled to the media , '' it read .\n",
      "\n",
      "Ferrara joined Juve late last season and steered the Turin powerhouses to second place in Serie A behind Inter .\n",
      "\n",
      "But his first full campaign in charge proved challenging after a promising start to the season .\n",
      "\n",
      "The Bianconeri have lost five of their last six games in Serie A and have slumped to sixth in the standings , four points behind Napoli , who hold the last Champions League qualifying spot .\n",
      "\n",
      "Zaccheroni will hope to get them on track with his first game against Lazio on Sunday .\n",
      "\n",
      "The 56-year-old has coached at a number of leading Serie A clubs and helped AC Milan to the 1999 Italian title , but it is his first job since being sacked by Torino in February 2007 .\n",
      "\n",
      "Ferrara , a former Italy international and Juventus defender , was given the reins despite his lack of experience , succeeding current Roma coach Claudio Ranieri , who was fired .\n",
      "\n",
      "Zaccheroni 's appointment ends , for now , media speculation that Liverpool manager Rafael Benitez would take charge at Juve , but the short-term nature of his contract until June raises questions about the permanence of his stay .\n",
      "\n",
      "Benitez acknowledged the speculation in his weekly press conference on Friday .\n",
      "\n",
      "`` I am focused on preparing my team for the game against Bolton . I know they -LRB- Juventus -RRB- were interested , that is part of the game now in football , but I am not ready to talk too much because I do n't want to lose my focus .\n",
      "\n",
      "`` When you are a manager and you have clubs asking -LRB- for you -RRB- , you have to be proud because they are a top side in Europe , but I am really happy here and want to do my job as best I can . ''\n",
      "\n",
      "@highlight\n",
      "\n",
      "Juventus sack coach Ciro Ferrara after a string of poor results in Serie A and Europe\n",
      "\n",
      "@highlight\n",
      "\n",
      "Ferrari replaced by former Milan coach Alberto Zaccheroni until the end of the season\n",
      "\n",
      "@highlight\n",
      "\n",
      "Juventus have slipped to sixth in Serie A after losing five of their last six games\n"
     ]
    }
   ],
   "source": [
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay! We have an output sentence. Let's compare it via ROUGE to the highlight that we reserved for comparing to this output at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vs Story\n",
      "===============\n",
      "ROUGE score: 0.0689655139595721\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "print('Output vs Story')\n",
    "print('='*15)\n",
    "print('ROUGE score:',rouge.get_scores(summary,highlights)[0]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is room for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
