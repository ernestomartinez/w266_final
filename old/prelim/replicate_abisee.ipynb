{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install rouge\n",
    "# !pip install sentencepiece\n",
    "# !pip install nomkl\n",
    "# !pip install datasets\n",
    "# !pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TFT5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import Dataset\n",
    "from rouge import Rouge\n",
    "import nltk.data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some functions for convenience later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_story(filename):\n",
    "    \"\"\"Given the CNN data file, reformats to separate the story from the highlights.\n",
    "    Highlights are returned as a single string\"\"\"\n",
    "    \n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    \n",
    "    # split the story and highlights\n",
    "    split_text = text.split('\\n\\n@highlight\\n\\n')\n",
    "    story = split_text[0]\n",
    "    highlights = split_text[1:]\n",
    "    \n",
    "    # return both, rejoining highlights as a single string\n",
    "    return story, '. '.join(highlights)+'.'\n",
    "\n",
    "def cos_sims(out_sent, ref_sents):\n",
    "    \"gets cosine similarities for an output sentence with respect to the highlight sentences. Returns the sum of values.\"\n",
    "    \n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\")                                                                                                                                                                                                   \n",
    "    \n",
    "    # get sentence level vectors with tf-idf\n",
    "    tfidf = vect.fit_transform([out_sent] + ref_sents)\n",
    "    \n",
    "    # get similarity matrix\n",
    "    similarity_mat = tfidf * tfidf.T\n",
    "    \n",
    "    # only values comparing \"out_sent\" with each sent in \"ref_sents\"\n",
    "    return similarity_mat.toarray()[:1,1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a T5 Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d6a9cb6fb74b9486f99df5a20813cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ad2a0e571541f1b6cf2e0d73e1bec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# t5 model objects\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0001d1afc246a7964130f43ae940af6bc6c57f01.story',\n",
       " '0002095e55fcbd3a2f366d9bf92a95433dc305ef.story',\n",
       " '00027e965c8264c35cc1bc55556db388da82b07f.story',\n",
       " '0002c17436637c4fe1837c935c04de47adb18e9a.story',\n",
       " '0003ad6ef0c37534f80b55b4235108024b407f0b.story']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of story files in our dataset\n",
    "textFiles = os.listdir('cnn_stories_tokenized')\n",
    "textFiles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get some baseline loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2349 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7795, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8156, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7631, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8409, grad_fn=<NllLossBackward>)\n",
      "tensor(3.4472, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#text_files = ['example.story', 'example1.story', 'example2.story']\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('cnn_stories_tokenized/'+textFiles[i])\n",
    "    \n",
    "    #train the model\n",
    "    input_ids = tokenizer('summarize: ' + story, return_tensors='pt').input_ids\n",
    "    labels = tokenizer(highlights, return_tensors='pt').input_ids\n",
    "    \n",
    "    # compute loss (this returns an array of things)\n",
    "    loss = model(input_ids=input_ids, labels=labels).loss\n",
    "    \n",
    "    # print loss (sum of array values above)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train/Dev/Test like Abisee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 passed, 10 passed, 15 passed, 20 passed, 25 passed, 30 passed, 35 passed, 40 passed, 45 passed, 50 passed, 55 passed, 60 passed, 65 passed, 70 passed, 75 passed, 80 passed, 85 passed, 90 passed, 95 passed, 100 passed, 105 passed, 110 passed, 115 passed, 120 passed, 125 passed, 130 passed, 135 passed, 140 passed, 145 passed, 150 passed, 155 passed, 160 passed, 165 passed, 170 passed, 175 passed, 180 passed, 185 passed, 190 passed, 195 passed, 200 passed, 205 passed, 210 passed, 215 passed, 220 passed, 225 passed, 230 passed, 235 passed, 240 passed, 245 passed, 250 passed, 255 passed, 260 passed, 265 passed, 270 passed, 275 passed, 280 passed, 285 passed, 290 passed, 295 passed, 300 passed, 305 passed, 310 passed, 315 passed, 320 passed, 325 passed, 330 passed, 335 passed, 340 passed, 345 passed, 350 passed, 355 passed, 360 passed, 365 passed, 370 passed, 375 passed, 380 passed, 385 passed, 390 passed, 395 passed, 400 passed, 405 passed, 410 passed, 415 passed, 420 passed, 425 passed, 430 passed, 435 passed, 440 passed, 445 passed, 450 passed, 455 passed, 460 passed, 465 passed, 470 passed, 475 passed, 480 passed, 485 passed, 490 passed, 495 passed, 500 passed, 505 passed, 510 passed, 515 passed, 520 passed, 525 passed, 530 passed, 535 passed, 540 passed, 545 passed, 550 passed, 555 passed, 560 passed, 565 passed, 570 passed, 575 passed, 580 passed, 585 passed, 590 passed, 595 passed, 600 passed, 605 passed, 610 passed, 615 passed, 620 passed, 625 passed, 630 passed, 635 passed, 640 passed, 645 passed, 650 passed, 655 passed, 660 passed, 665 passed, 670 passed, 675 passed, 680 passed, 685 passed, 690 passed, 695 passed, 700 passed, 705 passed, 710 passed, 715 passed, 720 passed, 725 passed, 730 passed, 735 passed, 740 passed, 745 passed, 750 passed, 755 passed, 760 passed, 765 passed, 770 passed, 775 passed, 780 passed, 785 passed, 790 passed, 795 passed, 800 passed, 805 passed, 810 passed, 815 passed, 820 passed, 825 passed, 830 passed, 835 passed, 840 passed, 845 passed, 850 passed, 855 passed, 860 passed, 865 passed, 870 passed, 875 passed, 880 passed, 885 passed, 890 passed, 895 passed, 900 passed, 905 passed, 910 passed, 915 passed, 920 passed, 925 passed, 930 passed, 935 passed, 940 passed, 945 passed, 950 passed, 955 passed, 960 passed, 965 passed, 970 passed, 975 passed, 980 passed, 985 passed, 990 passed, 995 passed, 1000 passed, \n",
      "\n",
      "time: 2.664992654323578\n"
     ]
    }
   ],
   "source": [
    "source_text = []\n",
    "target_text = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('cnn_stories_tokenized/'+textFiles[i])\n",
    "    \n",
    "    source_text.append(story)\n",
    "    target_text.append(highlights)\n",
    "    \n",
    "#     source_text.append(tokenizer('summarize: ' + story, return_tensors='tf').input_ids)\n",
    "#     target_text.append(tokenizer(highlights, return_tensors='tf').input_ids)\n",
    "    \n",
    "    if (i+1)%50 == 0:\n",
    "        print(i+1, \"passed\", end = ', ')\n",
    "        \n",
    "print('\\n\\ntime:', (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1k = pd.DataFrame(list(zip(source_text, target_text)),columns =['source', 'target'])\n",
    "train_1k = Dataset.from_pandas(train_1k)\n",
    "# train_1k.iloc[0,1]\n",
    "\n",
    "dataset = train_1k.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83b27db813e42008b32b4063bbe5163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1a710229dd409681a324b948289bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized_input = tokenizer(batch['source'], padding='max_length', truncation=True)\n",
    "    tokenized_label = tokenizer(batch['target'], padding='max_length', truncation=True)\n",
    "\n",
    "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
    "\n",
    "    return tokenized_input\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=512)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels', 'source', 'target'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='226' max='226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [226/226 38:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.360900</td>\n",
       "      <td>0.282724</td>\n",
       "      <td>20.055400</td>\n",
       "      <td>4.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.340200</td>\n",
       "      <td>0.281036</td>\n",
       "      <td>21.725900</td>\n",
       "      <td>4.603000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>21.845700</td>\n",
       "      <td>4.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>21.985800</td>\n",
       "      <td>4.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.270750</td>\n",
       "      <td>22.589400</td>\n",
       "      <td>4.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>0.271339</td>\n",
       "      <td>22.606100</td>\n",
       "      <td>4.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.266850</td>\n",
       "      <td>22.570800</td>\n",
       "      <td>4.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>0.266194</td>\n",
       "      <td>22.588700</td>\n",
       "      <td>4.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.269828</td>\n",
       "      <td>22.572000</td>\n",
       "      <td>4.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.266014</td>\n",
       "      <td>22.626400</td>\n",
       "      <td>4.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.266112</td>\n",
       "      <td>22.598900</td>\n",
       "      <td>4.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.269102</td>\n",
       "      <td>22.859000</td>\n",
       "      <td>4.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.268374</td>\n",
       "      <td>22.645300</td>\n",
       "      <td>4.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.266703</td>\n",
       "      <td>22.629700</td>\n",
       "      <td>4.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.265624</td>\n",
       "      <td>22.607900</td>\n",
       "      <td>4.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.266504</td>\n",
       "      <td>22.615400</td>\n",
       "      <td>4.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.268239</td>\n",
       "      <td>22.637200</td>\n",
       "      <td>4.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.266609</td>\n",
       "      <td>22.614700</td>\n",
       "      <td>4.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.265979</td>\n",
       "      <td>22.644200</td>\n",
       "      <td>4.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.265551</td>\n",
       "      <td>22.636800</td>\n",
       "      <td>4.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.265426</td>\n",
       "      <td>22.629500</td>\n",
       "      <td>4.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.280300</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>22.668800</td>\n",
       "      <td>4.411000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time: 38.63646587928136\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output_dir = 'model'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "    prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "    learning_rate=0.001,\n",
    "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "    save_steps=10, # How often to save a checkpoint\n",
    "    save_total_limit=1, # Number of maximum checkpoints to save\n",
    "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "    run_name='run_name', # Wandb run name\n",
    "    logging_steps=10, # How often to log loss to wandb\n",
    "    eval_steps=10, # How often to run evaluation on the val_set\n",
    "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "    greater_is_better=False # Best model is the one with the lowest loss, not highest.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir + '/model')\n",
    "\n",
    "print('\\n\\ntime:', (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How did Training affect the loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2349 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7725, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1319, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# SECOND LOOK\n",
    "\n",
    "our_model = T5ForConditionalGeneration.from_pretrained('model/model')\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('cnn_stories_tokenized/'+textFiles[i])\n",
    "    \n",
    "    #train the model\n",
    "    input_ids = tokenizer('summarize: ' + story, return_tensors='pt').input_ids\n",
    "    labels = tokenizer(highlights, return_tensors='pt').input_ids\n",
    "    \n",
    "    # compute loss (this returns an array of things)\n",
    "    loss = our_model(input_ids=input_ids, labels=labels).loss\n",
    "    \n",
    "    # print loss (sum of array values above)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('story_list.txt', 'w') as f:\n",
    "#     for item in textFiles:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the text to input/target format\n",
    "story, highlights = format_story('cnn_stories_tokenized/'+textFiles[1000])\n",
    "\n",
    "# encode the summary\n",
    "encoded = tokenizer.encode('summarize: ' + story.replace('\\n',' '), return_tensors='pt')\n",
    "\n",
    "# decode\n",
    "output = our_model.generate(encoded, num_beams=4, no_repeat_ngram_size=2,\n",
    "                         min_length=30, max_length=300, early_stopping=True)\n",
    "summary = tokenizer.decode(output[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the ouput compare to the reference summary (e.g. highlights)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "known highlights:\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "`` The problem still is there .\n",
      "\n",
      "The problem is in Washington , D.C. , '' says Murrieta mayor.\n",
      "\n",
      "Immigrant rights advocate denounces `` anti-immigrant hate language ''.\n",
      "\n",
      "140 undocumented Central American immigrants arrive in California from Texas.\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "summary sentences:\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "<pad> NEW : <unk> This is a failure to enforce federal law, '' says the national border patrol chief.\n",
      "\n",
      "The busloads of immigrants were taken to U.S. processing centers in San Diego and El Centro.\n",
      "\n",
      "Thousands of migrants have been detained in the United States since last month.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PRINT HIGHLIGHTS AND SUMMARY SENTENCES\n",
    "\n",
    "splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "highlights_split = splitter.tokenize(highlights)\n",
    "\n",
    "print('~'*100)\n",
    "print('known highlights:')\n",
    "print('~'*100)\n",
    "for i in range(len(highlights_split)-1):\n",
    "    print(highlights_split[i])\n",
    "    print('')\n",
    "\n",
    "print('')\n",
    "    \n",
    "summ_sentences = splitter.tokenize(summary)   \n",
    "\n",
    "print('~'*100)\n",
    "print('summary sentences:')\n",
    "print('~'*100)\n",
    "for i in range(len(summ_sentences)):\n",
    "    print(summ_sentences[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cosine Similarity to select sentence with most novel information (i.e. the sentence least similar to the highlights). We will leave one highlight out of this process to compare with the output via ROUGE at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novel Info:\n",
      "Thousands of migrants have been detained in the United States since last month.</s>\n",
      "\n",
      "Left out highlight:\n",
      "Protesters block them from being processed at the Murrieta Border Patrol station.\n"
     ]
    }
   ],
   "source": [
    "# for each summary sent, get the sum of the cosine similarity scores of the sent with all highlights\n",
    "# lowest score = most novel info\n",
    "\n",
    "\n",
    "scores = []\n",
    "for sent in summ_sentences:\n",
    "#     score = sum(cos_sims(sent,highlights.split('. ')))\n",
    "    score = sum(cos_sims(sent,highlights_split[:-1]))\n",
    "    scores.append(score)\n",
    "\n",
    "# output the sentence with the least similarity to highlights\n",
    "print('Novel Info:')\n",
    "print(summ_sentences[scores.index(min(scores))])\n",
    "print('')\n",
    "\n",
    "print('Left out highlight:')\n",
    "print(highlights_split[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay! We have an output sentence. Let's compare it via ROUGE to the highlight that we reserved for comparing to this output at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vs Story\n",
      "===============\n",
      "ROUGE score: 0.07692307195266304\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "print('Output vs Story')\n",
    "print('='*15)\n",
    "print('ROUGE score:',rouge.get_scores(summ_sentences[scores.index(min(scores))],highlights_split[-1])[0]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is room for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
