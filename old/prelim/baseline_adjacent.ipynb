{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5Model, TFT5ForConditionalGeneration, pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import *\n",
    "from rouge import Rouge\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning how to ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'f': 0.8571428521949189,\n",
      "              'p': 0.7777777777777778,\n",
      "              'r': 0.9545454545454546},\n",
      "  'rouge-2': {'f': 0.8510638248438207,\n",
      "              'p': 0.7692307692307693,\n",
      "              'r': 0.9523809523809523},\n",
      "  'rouge-l': {'f': 0.7999999951020409, 'p': 0.7, 'r': 0.9333333333333333}}]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[{'rouge-1': {'f': 0.5263157853601108,\n",
      "              'p': 0.37037037037037035,\n",
      "              'r': 0.9090909090909091},\n",
      "  'rouge-2': {'f': 0.44444444043209885, 'p': 0.3076923076923077, 'r': 0.8},\n",
      "  'rouge-l': {'f': 0.5999999955555556, 'p': 0.45, 'r': 0.9}}]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428521949189"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out this rouge package\n",
    "# googled to find, so we should do some research about a potential better package\n",
    "\n",
    "s1 = \"\"\"I am trying as best I can, using as many words as I can, to make this sentence as long as possible,\n",
    "        though it has little meaning.\"\"\"\n",
    "s2 = 'I am trying as best I can, using as many words as I can, to make this sentence as long as possible.'\n",
    "s3 = 'I am trying as best I can to make this sentence as long as possible.'\n",
    "s4 = 'I am trying to make this sentence as long as possible.'\n",
    "\n",
    "# ROUGE object\n",
    "rouge = Rouge()\n",
    "\n",
    "# get some scores\n",
    "print(rouge.get_scores(s1, s2))\n",
    "print('~'*70)\n",
    "print(rouge.get_scores(s1, s4))\n",
    "print('~'*70)\n",
    "rouge.get_scores(s1, s2)[0]['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5, let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# t5 model objects\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = TFT5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ORME, Tennessee (CNN) -- The drought in the Southeastern United States means more than just brown lawns to the folks in Orme, Tennessee. Water flows from their taps for just three hours each evening.\\n\\nA 1961 firetruck loads up with water from a hydrant in Alabama to haul back to Orme, Tennessee.\\n\\nThe mountain spring that supplies water to the town usually dries up at the end of summer, but just for a few days. This year it dried up early, on August 1, and hasn\\'t revived, leaving the town\\'s 145 residents high and dry and relying on water trucked in from the next state.\\n\\nEvery day at 6 p.m., Orme Mayor Tony Reames turns a big valve to release water from the town\\'s tank. When he turns the crank again at 9 p.m., taps in the town run dry.\\n\\n\"When they cut it back on we jump for joy,\" Orme resident Debbie Cash said. \"And then you only have it for three hours.\"\\n\\nThree hours to do all the laundry, bathing, dishwashing and animal watering that has to be done.  Watch how Cash copes Â»\\n\\nThe old mining town could be the canary in the coal mine for the rest of the region. Just 150 miles to the southeast, the 4.5 million people who live in and around Atlanta, Georgia, are nervously watching water levels go down at their major reservoir. The drought has highlighted an ongoing struggle between Georgia, Alabama and Florida over rights to water from the Chattahoochee River.\\n\\n\"All of these people that are on the river systems better take note, because once your streams and tributaries to the river start drying up, the river isn\\'t far behind,\" Reames said.  See photos of a Atlanta\\'s shrinking Lake Lanier reservoir Â»\\n\\nVolunteers take turns three days a week driving a tanker truck or Orme\\'s diesel-belching 1961 fire truck to a hydrant near Bridgeport, Alabama, 2Â½ miles down the road. Making several round trips, they haul about 25,000 gallons of water back to Orme each day.\\n\\nBridgeport, which gets its water from the Tennessee River, doesn\\'t charge its neighbor. Stevenson and New Hope, Alabama, also help out, occasionally bringing trucks full of water to the hydrant, where it\\'s transferred to the Orme trucks.  See where Orme has to go for water Â»\\n\\nBut things are looking up in Orme. A pipeline from Bridgeport is nearly complete, built with the help of a $378,000 grant from the federal government.\\n\\n\"With this new water coming in, then we\\'ll have it made,\" Cash said. \"Now we won\\'t have to worry about it no more.\"\\n\\nIn addition, an Austin, Texas, company called H2O Guard is planning to donate water-saving sink aerators, shower heads and toilet valves to everyone in Orme  on November 17, company spokesman Robert Easter said.\\n\\n\"We think we\\'re going to get another 90 gallons\\' savings per day per household,\" Easter said. \"That\\'ll make that little water tower in that town go from three hours to four hours without any change in anyone\\'s habits.\"\\n\\nReames said residents have found creative ways to conserve, flushing toilets with condensation water from air conditioners and undrinkable water from swimming pools that were filled early in the summer.\\n\\nIt\\'s a lesson for everyone.\\n\\n\"Cherish the water you got and be kind of careful with it,\" Cash said, \"because you never know if you will be out of water.\" E-mail to a friend\\n\\nCNN\\'s Jim Kavanagh contributed to this report.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the example story\n",
    "f = open('example.story','r')\n",
    "text = f.read()\n",
    "\n",
    "# separate the higlights from the main story\n",
    "split_text = text.split('\\n\\n@highlight\\n\\n')\n",
    "story = split_text[0]\n",
    "story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the article with our t5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# encode the summary\n",
    "encoded = tokenizer.encode('summarize: ' + story.replace('\\n',' '), return_tensors='tf')\n",
    "\n",
    "# decode\n",
    "output = model.generate(encoded, num_beams=4, no_repeat_ngram_size=2,\n",
    "                         min_length=30, max_length=300, early_stopping=True)\n",
    "summary = tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "highlights:\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Orme, Tennessee, has running water from 6 p.m. to 9 p.m.\n",
      "Town's spring ran dry in midst of Southeast drought\n",
      "Donated water is trucked in from Alabama\n",
      "Completion of pipeline will solve problem for good\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "summary sentences:\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "<pad> orme, tennessee, residents rely on water trucked in from the next state\n",
      "town's mountain spring usually dries up at the end of summer, but just for a few days\n",
      "this year it dried up early, on august 1, and hasn't revived\n",
      "4.5 million people in and around Atlanta, Georgia, are nervously watching water levels go down.\n"
     ]
    }
   ],
   "source": [
    "# PRINT HIGHLIGHTS AND SUMMARY SENTENCES\n",
    "\n",
    "highlights = split_text[1:]\n",
    "\n",
    "print('~'*100)\n",
    "print('highlights:')\n",
    "print('~'*100)\n",
    "for i in range(len(highlights)):\n",
    "    print(highlights[i])\n",
    "\n",
    "print('')\n",
    "    \n",
    "summ_sentences = summary.split('. ')   \n",
    "\n",
    "print('~'*100)\n",
    "print('summary sentences:')\n",
    "print('~'*100)\n",
    "for i in range(len(summ_sentences)):\n",
    "    print(summ_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get sentence with most novel information using ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novel Info:\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this year it dried up early, on august 1, and hasn't revived\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each summary sent, get the sum of the ROUGE scores of the sent with all highlights\n",
    "# not very sophisticated, i'm sure we'll come up with something better\n",
    "# but it's a start\n",
    "\n",
    "scores = []\n",
    "for sent in summ_sentences:\n",
    "    score = sum([rouge.get_scores(sent, highlight)[0]['rouge-1']['f'] for highlight in highlights])\n",
    "    scores.append(score)\n",
    "\n",
    "# output the sentence with the least similarity to highlights\n",
    "print('Novel Info:')\n",
    "summ_sentences[scores.index(min(scores))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about Cosine Similarity?\n",
    "\n",
    "We can use TF-IDF to vectorize the sentences, and use cosime similarity to find the sentence least like the highlights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity of s0 to:\n",
      "stf.Tensor(1, shape=(), dtype=int32) = 0.7907476749448838\n",
      "1\n",
      "stf.Tensor(2, shape=(), dtype=int32) = 0.6175531063761837\n",
      "1\n",
      "stf.Tensor(3, shape=(), dtype=int32) = 0.5452877544361474\n",
      "1\n",
      "stf.Tensor(4, shape=(), dtype=int32) = 0.0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# make up some similar sentences\n",
    "s0 = \"\"\"I am trying as best I can, using as many words as I can, to make this sentence as long as possible,\n",
    "        though it has little meaning.\"\"\"\n",
    "s1 = 'I am trying as best I can, using as many words as I can, to make this sentence as long as possible.'\n",
    "s2 = 'I am trying as best I can to make this sentence as long as possible.'\n",
    "s3 = 'I am trying to make this sentence as long as possible.'\n",
    "\n",
    "# add in a totally different sentence\n",
    "s4 = 'Liver tastes terrible.'\n",
    "\n",
    "def cos_sims(out_sent, ref_sents):\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\")                                                                                                                                                                                                   \n",
    "    tfidf = vect.fit_transform([out_sent] + ref_sents)  \n",
    "\n",
    "    similarity_mat = tfidf * tfidf.T\n",
    "\n",
    "    return similarity_mat.toarray()[:1,1:][0]\n",
    "\n",
    "similarities = cos_sims(s0,[s1,s2,s3,s4])\n",
    "\n",
    "print('similarity of s0 to:') \n",
    "for i in range(4):\n",
    "    print('s'+str(i+1),'=',similarities[i])\n",
    "    print(str(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get sentence with most novel information using Cosine Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novel Info:\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this year it dried up early, on august 1, and hasn't revived\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each summary sent, get the sum of the cosine similarity scores of the sent with all highlights\n",
    "# lowest score = most novel info\n",
    "\n",
    "scores = []\n",
    "for sent in summ_sentences:\n",
    "    score = sum(cos_sims(sent,highlights))\n",
    "    scores.append(score)\n",
    "\n",
    "# output the sentence with the least similarity to highlights\n",
    "print('Novel Info:')\n",
    "summ_sentences[scores.index(min(scores))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOOOOHOOO, this method results in the same sentence!\n",
    "\n",
    "#### BUT I didn't leave out a highlight to compare the sentence with. Let's run this again, but leave out one highlight. We'll use ROUGE to compare this left-out highlight to the target sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novel Info:\n",
      "this year it dried up early, on august 1, and hasn't revived\n",
      "\n",
      "Left Out Highlight:\n",
      "Completion of pipeline will solve problem for good\n",
      "\n",
      "How similar to left out highlight?\n",
      "ROUGE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#use cosine similarity to \n",
    "\n",
    "scores = []\n",
    "for sent in summ_sentences:\n",
    "    score = sum(cos_sims(sent,highlights[:-1]))\n",
    "    scores.append(score)\n",
    "\n",
    "# output the sentence with the least similarity to highlights\n",
    "print('Novel Info:')\n",
    "novel = summ_sentences[scores.index(min(scores))]\n",
    "print(novel)\n",
    "\n",
    "print('\\nLeft Out Highlight:')\n",
    "print(highlights[-1])\n",
    "\n",
    "print('\\nHow similar to left out highlight?')\n",
    "print('ROUGE score:',rouge.get_scores(novel,highlights[-1])[0]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUCH.... ROUGE score was zero.\n",
    "### But we know this was a decent output right? It gave some novel info (the 8/1 date). So we need to think of a new way of evaluating. What about not excluding any highlights, and getting ROUGE for the output with the entire article?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vs Story\n",
      "===============\n",
      "ROUGE score: 0.03355704658528895\n"
     ]
    }
   ],
   "source": [
    "print('Output vs Story')\n",
    "print('='*15)\n",
    "print('ROUGE score:',rouge.get_scores(novel,story)[0]['rouge-1']['f'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
