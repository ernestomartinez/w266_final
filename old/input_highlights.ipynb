{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install rouge\n",
    "# !pip install sentencepiece\n",
    "# !pip install nomkl\n",
    "# !pip install datasets\n",
    "# !pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/futureperfect6/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, TFT5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import Dataset\n",
    "from rouge import Rouge\n",
    "import nltk.data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some functions for convenience later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_story(filename):\n",
    "    \"\"\"Given the CNN data file, reformats to separate the story from the highlights.\n",
    "    Highlights are returned as a single string\"\"\"\n",
    "    \n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    \n",
    "    # split the story and highlights\n",
    "    split_text = text.split('\\n\\n@highlight\\n\\n')\n",
    "    story = split_text[0]\n",
    "    highlights = split_text[1:]\n",
    "    \n",
    "    # return both\n",
    "    return story, highlights#'. '.join(highlights)+'.'\n",
    "\n",
    "def cos_sims(out_sent, ref_sents):\n",
    "    \"gets cosine similarities for an output sentence with respect to the highlight sentences. Returns the sum of values.\"\n",
    "    \n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\")                                                                                                                                                                                                   \n",
    "    \n",
    "    # get sentence level vectors with tf-idf\n",
    "    tfidf = vect.fit_transform([out_sent] + ref_sents)\n",
    "    \n",
    "    # get similarity matrix\n",
    "    similarity_mat = tfidf * tfidf.T\n",
    "    \n",
    "    # only values comparing \"out_sent\" with each sent in \"ref_sents\"\n",
    "    return similarity_mat.toarray()[:1,1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a T5 Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# t5 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "def tokenize(batch):\n",
    "    \"\"\"Applies tokenizer to a whole dataset at once. Input is a dataset with raw text data, \n",
    "    and output is a dataset with tokenized data\"\"\"\n",
    "    \n",
    "    tokenized_input = tokenizer(batch['source'], padding='max_length', truncation=True)\n",
    "    tokenized_label = tokenizer(batch['target'], padding='max_length', truncation=True)\n",
    "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92579 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>story</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>duplicate</th>\n",
       "      <th>source</th>\n",
       "      <th>highlights</th>\n",
       "      <th>broken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01.story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef.story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f.story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a.story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b.story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           story  train  \\\n",
       "0           0  0001d1afc246a7964130f43ae940af6bc6c57f01.story      1   \n",
       "1           1  0002095e55fcbd3a2f366d9bf92a95433dc305ef.story      1   \n",
       "2           2  00027e965c8264c35cc1bc55556db388da82b07f.story      1   \n",
       "3           3  0002c17436637c4fe1837c935c04de47adb18e9a.story      1   \n",
       "4           4  0003ad6ef0c37534f80b55b4235108024b407f0b.story      1   \n",
       "\n",
       "   validation  test  duplicate source  highlights  broken  \n",
       "0           0     0          0      0           4       0  \n",
       "1           0     0          0      0           4       0  \n",
       "2           0     0          0      0           3       0  \n",
       "3           0     0          0      0           4       0  \n",
       "4           0     0          0      0           3       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load metadata\n",
    "cnn_meta = pd.read_csv('cnn_meta.csv')\n",
    "print(len(cnn_meta.index),'rows')\n",
    "cnn_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting\n",
    "\n",
    "Right now, we have a text file for each story. T5 requires a single matrix (a dataset object is perfect) with source/target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 passed, \n",
      "\n",
      "time: 0.2814207275708516 minutes\n",
      "Dataset({\n",
      "    features: ['source', 'target'],\n",
      "    num_rows: 357\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-LRB- CNN -RRB- -- If you travel by plane and ...</td>\n",
       "      <td>Hawaiian Airlines again lands at No. 1 in on-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-LRB- CNN -RRB- -- If you travel by plane and ...</td>\n",
       "      <td>The Airline Quality Rankings Report looks at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-LRB- CNN -RRB- -- If you travel by plane and ...</td>\n",
       "      <td>ExpressJet and American Airlines had the worst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-LRB- CNN -RRB- -- If you travel by plane and ...</td>\n",
       "      <td>Virgin America had the best baggage handling ;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- CNN -RRB- For the second time during his...</td>\n",
       "      <td>The 15 new cardinals will be installed on Febr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  -LRB- CNN -RRB- -- If you travel by plane and ...   \n",
       "1  -LRB- CNN -RRB- -- If you travel by plane and ...   \n",
       "2  -LRB- CNN -RRB- -- If you travel by plane and ...   \n",
       "3  -LRB- CNN -RRB- -- If you travel by plane and ...   \n",
       "4  -LRB- CNN -RRB- For the second time during his...   \n",
       "\n",
       "                                              target  \n",
       "0  Hawaiian Airlines again lands at No. 1 in on-t...  \n",
       "1  The Airline Quality Rankings Report looks at t...  \n",
       "2  ExpressJet and American Airlines had the worst...  \n",
       "3  Virgin America had the best baggage handling ;...  \n",
       "4  The 15 new cardinals will be installed on Febr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text_train = []\n",
    "target_text_train = []\n",
    "\n",
    "# get list of training files\n",
    "train_files = cnn_meta[cnn_meta['train']==1].reset_index()['story']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# for i in range(len(train_files)):\n",
    "for i in range(100):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('ernesto/cnn_stories_tokenized/'+ train_files[i+10])\n",
    "    \n",
    "    # format data as story/single highlight pairs\n",
    "    for j in range(len(highlights)):\n",
    "        source_text_train.append('\\n\\n@highlight\\n\\n'.join([story]+highlights[:j]+highlights[j+1:]))\n",
    "        target_text_train.append(highlights[j])\n",
    "    \n",
    "    if (i+1)%100 == 0:\n",
    "        print(i+1, \"passed\", end = ', ')\n",
    "\n",
    "# print the time this took in minutes\n",
    "print('\\n\\ntime:', (time.time()-start)/60,'minutes')\n",
    "\n",
    "train_df = pd.DataFrame(list(zip(source_text_train, target_text_train)),columns =['source', 'target'])\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "print(train_dataset)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXAMPLE INPUT TEXT\n",
      "============================================================\n",
      "-LRB- CNN -RRB- -- If you travel by plane and arriving on time makes a difference , try to book on Hawaiian Airlines . In 2012 , passengers got where they needed to go without delay on the carrier more than nine times out of 10 , according to a study released on Monday .\n",
      "\n",
      "In fact , Hawaiian got even better from 2011 , when it had a 92.8 % on-time performance . Last year , it improved to 93.4 % .\n",
      "\n",
      "The Airline Quality Rankings Report looks at the 14 largest U.S. airlines and is based on an analysis of U.S. Department of Transportation figures . It 's co-authored by Brent Bowen , the head of the Department of Aviation Technology at Purdue University , and Dean Headley of Wichita State .\n",
      "\n",
      "In addition to on-time performance , the joint project looks at three other categories : rate of consumer complaints , mishandled bags and denied boarding performance .\n",
      "\n",
      "At a time when U.S. airlines are a whipping post for passenger complaints about crowded flights , tight seats , costly tickets and unsatisfactory service , there is a glimmer of hope .\n",
      "\n",
      "Eight airlines improved their on-time arrival performance in 2012 . Nine of the 14 rated had an on-time arrival percentage of more than 80 % .\n",
      "\n",
      "ExpressJet and American Airlines had the worst on-time performance -LRB- 76.9 % -RRB- last year , according to the data gathered in the 23rd annual report .\n",
      "\n",
      "Virgin America had the best baggage handling rate of all the airlines -LRB- 0.87 misplaced bags per 1,000 passengers . -RRB- American Eagle showed improvement from 2011 but still came in last , fumbling baggage at a rate of 5.80 mishandled bags per 1,000 passengers .\n",
      "\n",
      "When it came to complaints last year , Southwest again had the lowest consumer rate -LRB- 0.25 per 100,000 passengers -RRB- while the distinction of being the airline with the highest consumer complaint rate went to United Airlines -LRB- 4.24 per 100,000 . -RRB-\n",
      "\n",
      "Seven of the world 's most entertaining airports\n",
      "\n",
      "Boeing does ` final ' battery test on 787 Dreamliner\n",
      "\n",
      "FAA delays closures of 149 control towers\n",
      "\n",
      "@highlight\n",
      "\n",
      "The Airline Quality Rankings Report looks at the 14 largest U.S. airlines\n",
      "\n",
      "@highlight\n",
      "\n",
      "ExpressJet and American Airlines had the worst on-time performance\n",
      "\n",
      "@highlight\n",
      "\n",
      "Virgin America had the best baggage handling ; Southwest had lowest complaint rate\n",
      "============================================================\n",
      "EXAMPLE TARGET TEXT\n",
      "============================================================\n",
      "Hawaiian Airlines again lands at No. 1 in on-time performance\n"
     ]
    }
   ],
   "source": [
    "print('='*60+'\\nEXAMPLE INPUT TEXT\\n'+'='*60)\n",
    "print(source_text_train[0])\n",
    "print('='*60+'\\nEXAMPLE TARGET TEXT\\n'+'='*60)\n",
    "print(target_text_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time: 0.0857517917950948 minutes\n",
      "Dataset({\n",
      "    features: ['source', 'target'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "source_text_val = []\n",
    "target_text_val = []\n",
    "\n",
    "# get list of validation files\n",
    "val_files = cnn_meta[cnn_meta['validation']==1].reset_index()['story']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# for i in range(len(val_files)):\n",
    "for i in range(20):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('ernesto/cnn_stories_tokenized/'+ val_files[i])\n",
    "    \n",
    "    for j in range(len(highlights)):\n",
    "        source_text_val.append('\\n\\n@highlight\\n\\n'.join([story]+highlights[:j]+highlights[j+1:]))\n",
    "        target_text_val.append(highlights[j])\n",
    "    \n",
    "#     source_text.append(tokenizer('summarize: ' + story, return_tensors='tf').input_ids)\n",
    "#     target_text.append(tokenizer(highlights, return_tensors='tf').input_ids)\n",
    "    \n",
    "    if (i+1)%100 == 0:\n",
    "        print(i+1, \"passed\", end = ', ')\n",
    "\n",
    "# print the time this took in minutes\n",
    "print('\\n\\ntime:', (time.time()-start)/60,'minutes')\n",
    "\n",
    "val_df = pd.DataFrame(list(zip(source_text_val, target_text_val)),columns =['source', 'target'])\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get some baseline loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6362, grad_fn=<NllLossBackward>)\n",
      "tensor(3.1221, grad_fn=<NllLossBackward>)\n",
      "tensor(4.4120, grad_fn=<NllLossBackward>)\n",
      "tensor(4.4682, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3808, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# check some stories for pre-training loss\n",
    "for i in range(5):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('ernesto/cnn_stories_tokenized/'+val_files[i])\n",
    "    \n",
    "    #train the model\n",
    "    input_ids = tokenizer('summarize: ' + '\\n\\n@highlight\\n\\n'.join([story]+highlights[1:]),\n",
    "                          return_tensors='pt').input_ids\n",
    "    labels = tokenizer(highlights[0], return_tensors='pt').input_ids\n",
    "    \n",
    "    # compute loss (this returns an array of things)\n",
    "    loss = model(input_ids=input_ids, labels=labels).loss\n",
    "    \n",
    "    # print loss (sum of array values above)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688a7c3932274d75ad9744cce39fe006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3dbc10aec244a1834ab29aaca0c2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = train_dataset.map(tokenize, batched=True, batch_size=512)\n",
    "val_tokenized = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels', 'source', 'target'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 09:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time: 10.137892361481985 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output_dir = 'input_highlights_model'\n",
    "\n",
    "# training arguments to feed to Trainer object\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir, # trained model will be saved here\n",
    "    num_train_epochs = 2,\n",
    "    per_device_train_batch_size = 8, # number of examples per batch\n",
    "    per_device_eval_batch_size = 8, # number of examples per batch\n",
    "    eval_accumulation_steps = 1,\n",
    "    prediction_loss_only = True,\n",
    "    learning_rate = 0.001,\n",
    "    evaluation_strategy = 'steps',\n",
    "    save_steps = 10,\n",
    "    save_total_limit = 1,\n",
    "    remove_unused_columns = True,\n",
    "    run_name = 'run_name',\n",
    "    logging_steps = 500, # print loss after this many steps\n",
    "    eval_steps = 500, # calculate loss after this many steps\n",
    "    logging_first_step = False,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"loss\", \n",
    "    greater_is_better = False\n",
    ")\n",
    "\n",
    "# create Trainer to feed the train/dev data\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_tokenized,\n",
    "    eval_dataset = val_tokenized\n",
    ")\n",
    "\n",
    "# train the model and save it to our directory\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir + '/model')\n",
    "\n",
    "# print the time this took in minutes\n",
    "print('\\n\\ntime:', (time.time()-start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How did Training affect the loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0389, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0359, grad_fn=<NllLossBackward>)\n",
      "tensor(4.0702, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7790, grad_fn=<NllLossBackward>)\n",
      "tensor(3.1778, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "### Check the same stories as before and pray the loss has decreased ###\n",
    "\n",
    "# load our model\n",
    "baseline_model = T5ForConditionalGeneration.from_pretrained('baseline_model/model')\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # get formatted input and target\n",
    "    story, highlights = format_story('ernesto/cnn_stories_tokenized/'+val_files[i])\n",
    "    \n",
    "    #train the model\n",
    "    input_ids = tokenizer('summarize: ' + '\\n\\n@highlight\\n\\n'.join([story]+highlights[1:]),\n",
    "                                                                    return_tensors='pt').input_ids\n",
    "    labels = tokenizer(highlights[0], return_tensors='pt').input_ids\n",
    "    \n",
    "    # compute loss (this returns an array of things)\n",
    "    loss = baseline_model(input_ids=input_ids, labels=labels).loss\n",
    "    \n",
    "    # print loss (sum of array values above)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> <unk> The Dukes of Hazzard '' ran until 1985 and spawned television movies, an animated series and video games</s>\n",
      "\n",
      "<pad> It doesn't matter what anyone says, he is presumed to be innocent. A request for comment from an attorney was not returned</s>\n",
      "\n",
      "<pad> <unk> No challenge poses more of a public threat than climate change, '' he says.<pad><pad> English lawmakers are suing the EPA for failing to reframe the issue</s>\n",
      "\n",
      "<pad> A clip of the video features two men holding hands, a gay couple says's getting married this summer to someone I really care about</s>\n",
      "\n",
      "<pad> Rubio is a fierce opponent of <unk> Obamacare '' and wants to repeal the law. He has warned Cuba is taking advantage of the U.S.</s>\n",
      "\n",
      "ROUGE F1 (mean): 0.17037628522831902\n",
      "ROUGE F1 (best): 0.23547359592824982\n"
     ]
    }
   ],
   "source": [
    "# for scoring outputs\n",
    "rouge = Rouge()\n",
    "\n",
    "# get list of training files\n",
    "test_files = cnn_meta[cnn_meta['test']==1].reset_index()['story']\n",
    "\n",
    "mean_rouge = []\n",
    "max_rouge = []\n",
    "\n",
    "# for i in range(len(test_files)):\n",
    "for i in range(5):\n",
    "    # format the text to input/target format\n",
    "    story, highlights = format_story('ernesto/cnn_stories_tokenized/'+test_files[i])\n",
    "\n",
    "    # encode the input\n",
    "    encoded = tokenizer.encode('summarize: ' + story.replace('\\n',' '), return_tensors='pt')\n",
    "\n",
    "    # generate the output\n",
    "    output = baseline_model.generate(encoded, num_beams=4, no_repeat_ngram_size=2,\n",
    "                             min_length=30, max_length=300, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0])\n",
    "    print(summary)\n",
    "    print('')\n",
    "    \n",
    "    # get ROUGE scores between thoutput and highlights\n",
    "    scores = [rouge.get_scores(summary,highlight)[0]['rouge-1']['f'] for highlight in highlights]\n",
    "\n",
    "    mean_rouge.append(np.mean(scores))\n",
    "    max_rouge.append(max(scores))\n",
    "\n",
    "print('ROUGE F1 (mean):',np.mean(mean_rouge))\n",
    "print('ROUGE F1 (best):',np.mean(max_rouge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
